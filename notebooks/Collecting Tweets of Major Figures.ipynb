{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook collected recent tweets from major political figures on Twitter\n",
    "!pip install tweepy\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = \"1bj67gLRJ2t5ElTaG19sZUwG8\"\n",
    "consumer_secret = \"U1I5gjwI7D45EIAOtkXwokYmX0KjpOGOQmoQa6UbLefXVBy9Xt\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc = []\n",
    "final_t = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = pd.to_datetime('1/1/20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the most recent 3240 tweets for users with this function\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    # auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = [] \n",
    "        \n",
    "    initial = True\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "        \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while alltweets[-1].created_at > year_start:\n",
    "        \n",
    "        try:\n",
    "            #all subsiquent requests use the max_id param to prevent duplicates\n",
    "            new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "            print(len(alltweets), end=' ')\n",
    "\n",
    "        except tweepy.TweepError:\n",
    "            print('PAUSE')\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print(oldest.created_at)\n",
    "            \n",
    "    return alltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "canidates_Rep = ['realDonaldTrump', 'Mike_Pence', 'POTUS', 'VP']\n",
    "canidates_Dem = ['JoeBiden', 'KamalaHarris', 'SenKamalaHarris']\n",
    "politicians_Rep = ['DanCrenshawTX', 'SteveScalise', 'GOPLeader', 'senatemajldr', 'newtgingrich', 'SpeakerBoehner', 'MittRomney', 'tedcruz', 'SpeakerRyan', 'marcorubio']\n",
    "politicians_Dem = ['AOC', 'SpeakerPelosi', 'IlhanMN', 'CoryBooker', 'ewarren', 'BernieSanders', 'BarackObama', 'HillaryClinton', 'NYGovCuomo', 'PeteButtigieg']\n",
    "pundits_Rep = ['benshapiro', 'RubinReport', 'glennbeck', 'scrowder', 'seanhannity', 'TuckerCarlson', 'charliekirk11', 'RealCandaceO', 'DonaldJTrumpJr', 'RealRLimbaugh']\n",
    "pundits_Dem = ['maddow', 'Trevornoah', 'iamjohnoliver', 'StephenAtHome', 'sethmeyers', 'billmaher', 'VanJones68', 'shaunking', 'RBReich', 'iamsambee']\n",
    "organizations_Rep = ['WSJ', 'FoxNews', 'nypost', 'dcexaminer', 'OANN', 'WashTimes', 'reason', 'BreitbartNews', 'FDRLST', 'newsmax']\n",
    "organizations_Dem = ['TheAtlantic', 'business', 'CNNPolitics', 'MSNBC', 'guardian', 'nytimes', 'nprpolitics', 'washingtonpost', 'voxdotcom', 'BuzzFeedNews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total list is simply all of the different lists added together\n",
    "total_list="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for account in total_list:\n",
    "    tweet = get_all_tweets(account)\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc += users\n",
    "final_t += tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_acc, open(\"accounts.p\", \"wb\" ))\n",
    "pickle.dump(final_t, open(\"tweets.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
